{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News Headlines Sentiment Classification: Machine Learning Approah.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "f_e0hPbMqmEd",
        "colab_type": "code",
        "outputId": "ff18efac-759f-4c4a-9ed7-18f1c5f63d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import nltk, re, time\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oLXBlL2srLJF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/two_sigma_dataset/news_sample.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7wHOOsEfsRDo",
        "colab_type": "code",
        "outputId": "0996e21e-3593-467e-f527-483a2d4b8db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/two_sigma_dataset/news_sample.csv')\n",
        "\n",
        "# select the relevant columns\n",
        "df = data[['headline','sentimentClass']]\n",
        "\n",
        "# build a function that cleanse the data\n",
        "def clean_text(headline):\n",
        "  \"\"\"cleaning data\"\"\"\n",
        "  headline = headline.lower().split()\n",
        "  stopword = set(stopwords.words(\"english\"))\n",
        "  headline = [word for word in headline if not word in stopword]\n",
        "  headline = \" \".join(headline)\n",
        "  headline = re.sub('[^a-zA-z0-9\\s]','',headline)\n",
        "  return headline\n",
        "\n",
        "# apply the cleaning data function to the 'headline' columns of df\n",
        "df['headline'] = df['headline'].apply(clean_text)\n",
        "\n",
        "# build a function that tokenize the headlines\n",
        "def tokenize(feature):\n",
        "  max_features = 50\n",
        "  tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "  tokenizer.fit_on_texts(feature.values)\n",
        "  X = tokenizer.texts_to_sequences(feature.values)\n",
        "  X = pad_sequences(X)\n",
        "  return X\n",
        "\n",
        "# build a function that categorise the target variable\n",
        "def categorize(target):\n",
        "  if target == 0:\n",
        "    target = 'Neutral'\n",
        "  elif target == 1:\n",
        "    target = 'Positive'\n",
        "  else:\n",
        "    target = 'Negative'   \n",
        "  return target\n",
        "\n",
        "X = df['headline']\n",
        "y = df['sentimentClass']\n",
        "\n",
        "# tokenize the headlines which will be vectorised so that it can be fed in the neural network\n",
        "X = tokenize(X)\n",
        "\n",
        "# categorise the target and then do one-hot-encoding so that it can be fed in the neural network\n",
        "y = y.apply(categorize)\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QVG7EFCar1-G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import libraries for machine learning\n",
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hiLYoDFUuJgn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build pipelines with hyperparameters\n",
        "\n",
        "pipelines = {\n",
        "    'rf' : make_pipeline(RandomForestClassifier(random_state=123)),\n",
        "    'gb' : make_pipeline(GradientBoostingClassifier(random_state=123)),\n",
        "    'xgb': make_pipeline(XGBClassifier(random_state=123)),\n",
        "    'ada': make_pipeline(AdaBoostClassifier(random_state=123))\n",
        "}\n",
        "\n",
        "rf_hyperparameters = {'randomforestclassifier__n_estimators':[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]}\n",
        "gb_hyperparameters = {'gradientboostingclassifier__n_estimators':[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]}\n",
        "xgb_hyperparameters = {'xgbclassifier__n_estimators':[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] }\n",
        "ada_hyperparameters = {'adaboostclassifier__n_estimators':[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]}\n",
        "\n",
        "hyperparameters = {\n",
        "    'rf' : rf_hyperparameters,\n",
        "    'gb' : gb_hyperparameters,\n",
        "    'xgb': xgb_hyperparameters,\n",
        "    'ada':ada_hyperparameters\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4oTRCMUQurCI",
        "colab_type": "code",
        "outputId": "9fb7eccf-ae0a-4ce3-ea57-43f1b592c8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "# adopt gridsearchCV to tune hyperparameters\n",
        "fitted_models = {}\n",
        "\n",
        "for name, pipeline in pipelines.items():\n",
        "    model = GridSearchCV(pipeline, hyperparameters[name], cv=5, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "    fitted_models[name] = model\n",
        "    print(name, 'has been fitted.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rf has been fitted.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "gb has been fitted.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "xgb has been fitted.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ada has been fitted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NUXpkKf65NQw",
        "colab_type": "code",
        "outputId": "62c913d9-7c1b-4244-93df-312f2ad54c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "cell_type": "code",
      "source": [
        "print('The fitted best score for each model: \\n')\n",
        "for name, model in fitted_models.items():\n",
        "  print(name, model.best_score_)\n",
        "  \n",
        "print('\\n', '-----'*10, '\\n')\n",
        "\n",
        "print('The accuracy  score for each model: \\n')\n",
        "for name, model in fitted_models.items():\n",
        "  print(name, accuracy_score(y_test, model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The fitted best score for each model: \n",
            "\n",
            "rf 0.5571428571428572\n",
            "gb 0.5428571428571428\n",
            "xgb 0.5\n",
            "ada 0.45714285714285713\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "The accuracy  score for each model: \n",
            "\n",
            "rf 0.4\n",
            "gb 0.4\n",
            "xgb 0.4\n",
            "ada 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5xA5nGXp8Pdj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}